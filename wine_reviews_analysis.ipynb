{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import csv\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import model_evaluation_utils as meu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset (already have isolated the two columns for this analysis)\n",
    "wine = pd.read_csv('winemag_filt.csv')\n",
    "\n",
    "# Filter for 15 most popular wine varieties in the US\n",
    "top15 = ['Pinot Noir','Chardonnay','Cabernet Sauvignon',\n",
    "         'Red Blend','Riesling','Sauvignon Blanc','Syrah',\n",
    "         'Rose','Merlot','Zinfandel','Malbec', 'White Blend',\n",
    "        'Pinot Gris','Pinot Grigio','Shiraz','Moscato', 'Muscat']\n",
    "\n",
    "wine = wine[wine.variety.isin(top15)]\n",
    "\n",
    "# Take a random sample of 10000 observations from that filtered set\n",
    "wine_samp = wine.sample(n=10000, random_state=27)\n",
    "\n",
    "# Format columns as lists\n",
    "corpus = wine_samp['description'].values.tolist()\n",
    "labels = wine_samp['variety'].values.tolist()\n",
    "\n",
    "labels = [v.replace('Moscato', 'Mo/uscat(o)') for v in labels]\n",
    "labels = [v.replace('Muscat', 'Mo/uscat(o)') for v in labels]\n",
    "labels = [v.replace('Pinot Gris', 'Pinot Gris/Grigio') for v in labels]\n",
    "labels = [v.replace('Pinot Grigio', 'Pinot Gris/Grigio') for v in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accented char function\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special char function\n",
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', parse=True, tag=True, entity=True)\n",
    "\n",
    "# Lemmatization function (version of stemming that maintains English spellings)\n",
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer function\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "def remove_stopwords(text, is_lower_case=False, stopwords=stopword_list):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopwords]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the functions together now!\n",
    "def normalize_corpus(corpus,\n",
    "                     accented_char_removal=True, text_lower_case=True, \n",
    "                     text_lemmatization=True, special_char_removal=True, \n",
    "                     stopword_removal=True, remove_digits=True):\n",
    "    \n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "        # remove accented characters\n",
    "        if accented_char_removal:\n",
    "            doc = remove_accented_chars(doc)\n",
    "        # lowercase the text    \n",
    "        if text_lower_case:\n",
    "            doc = doc.lower()\n",
    "        # remove extra newlines\n",
    "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
    "        # lemmatize text\n",
    "        if text_lemmatization:\n",
    "            doc = lemmatize_text(doc)\n",
    "        # remove special characters and\\or digits    \n",
    "        if special_char_removal:\n",
    "            # insert spaces between special characters to isolate them    \n",
    "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "            doc = remove_special_characters(doc, remove_digits=remove_digits)  \n",
    "        # remove extra whitespace\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        # remove stopwords\n",
    "        if stopword_removal:\n",
    "            doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
    "            \n",
    "        normalized_corpus.append(doc)\n",
    "        \n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying to the data\n",
    "norm_corpus = normalize_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making training and test sets\n",
    "train_corpus, test_corpus, train_label_names, test_label_names = train_test_split(norm_corpus, labels, test_size=0.3, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Train Count</th>\n",
       "      <th>Test Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>1267</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>1083</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>870</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red Blend</td>\n",
       "      <td>803</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Riesling</td>\n",
       "      <td>456</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>440</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Syrah</td>\n",
       "      <td>389</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rose</td>\n",
       "      <td>329</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Merlot</td>\n",
       "      <td>280</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Zinfandel</td>\n",
       "      <td>273</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Malbec</td>\n",
       "      <td>234</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pinot Gris/Grigio</td>\n",
       "      <td>228</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>White Blend</td>\n",
       "      <td>221</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shiraz</td>\n",
       "      <td>91</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mo/uscat(o)</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Target Label  Train Count  Test Count\n",
       "3           Pinot Noir         1267         517\n",
       "0           Chardonnay         1083         480\n",
       "8   Cabernet Sauvignon          870         361\n",
       "1            Red Blend          803         368\n",
       "6             Riesling          456         198\n",
       "4      Sauvignon Blanc          440         191\n",
       "7                Syrah          389         193\n",
       "2                 Rose          329         141\n",
       "13              Merlot          280         104\n",
       "5            Zinfandel          273          96\n",
       "10              Malbec          234         113\n",
       "9    Pinot Gris/Grigio          228          96\n",
       "12         White Blend          221          91\n",
       "11              Shiraz           91          26\n",
       "14         Mo/uscat(o)           36          25"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table of distribution of varities in test, training datasets\n",
    "trd = dict(Counter(train_label_names))\n",
    "tsd = dict(Counter(test_label_names))\n",
    "\n",
    "(pd.DataFrame([[key, trd[key], tsd[key]] for key in trd], \n",
    "             columns=['Target Label', 'Train Count', 'Test Count'])\n",
    ".sort_values(by=['Train Count', 'Test Count'],\n",
    "             ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build Bag of Words features on train articles\n",
    "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0)\n",
    "cv_train_features = cv.fit_transform(train_corpus)\n",
    "\n",
    "# transform test articles into features\n",
    "cv_test_features = cv.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.60953058 0.60271041 0.62027123 0.62848962 0.6025825 ]\n",
      "Mean CV Accuracy: 0.6127168697541164\n",
      "Test Accuracy: 0.6293333333333333\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes model!\n",
    "mnb = MultinomialNB(alpha=1)\n",
    "mnb.fit(cv_train_features, train_label_names)\n",
    "mnb_bow_cv_scores = cross_val_score(mnb, cv_train_features, train_label_names, cv=5)\n",
    "mnb_bow_cv_mean_score = np.mean(mnb_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', mnb_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', mnb_bow_cv_mean_score)\n",
    "mnb_bow_test_score = mnb.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', mnb_bow_test_score)\n",
    "\n",
    "# CV Accuracy (5-fold): [0.60953058 0.60271041 0.62027123 0.62848962 0.6025825 ]\n",
    "# Mean CV Accuracy: 0.6127168697541164\n",
    "# Test Accuracy: 0.6293333333333333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.68136558 0.68259629 0.70235546 0.68432355 0.70301291]\n",
      "Mean CV Accuracy: 0.6907307580896089\n",
      "Test Accuracy: 0.7043333333333334\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model!\n",
    "lr = LogisticRegression(penalty='l2', max_iter=100, C=1, random_state=27)\n",
    "lr.fit(cv_train_features, train_label_names)\n",
    "lr_bow_cv_scores = cross_val_score(lr, cv_train_features, train_label_names, cv=5)\n",
    "lr_bow_cv_mean_score = np.mean(lr_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', lr_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', lr_bow_cv_mean_score)\n",
    "lr_bow_test_score = lr.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', lr_bow_test_score)\n",
    "\n",
    "# CV Accuracy (5-fold): [0.68136558 0.68259629 0.70235546 0.68432355 0.70301291]\n",
    "# Mean CV Accuracy: 0.6907307580896089\n",
    "# Test Accuracy: 0.7043333333333334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.61664296 0.63623395 0.65453248 0.6313529  0.65853659]\n",
      "Mean CV Accuracy: 0.639459774296731\n",
      "Test Accuracy: 0.6536666666666666\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC model!\n",
    "svm = LinearSVC(penalty='l2', C=1, random_state=27)\n",
    "svm.fit(cv_train_features, train_label_names)\n",
    "svm_bow_cv_scores = cross_val_score(svm, cv_train_features, train_label_names, cv=5)\n",
    "svm_bow_cv_mean_score = np.mean(svm_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svm_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', svm_bow_cv_mean_score)\n",
    "svm_bow_test_score = svm.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svm_bow_test_score)\n",
    "\n",
    "# CCV Accuracy (5-fold): [0.61664296 0.63623395 0.65453248 0.6313529  0.65853659]\n",
    "# Mean CV Accuracy: 0.639459774296731\n",
    "# Test Accuracy: 0.6536666666666666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.6230441  0.62624822 0.63526053 0.62848962 0.63271162]\n",
      "Mean CV Accuracy: 0.6291508167210028\n",
      "Test Accuracy: 0.6573333333333333\n"
     ]
    }
   ],
   "source": [
    "# SDGClassifier!\n",
    "svm_sgd = SGDClassifier(loss='hinge', penalty='l2', max_iter=5, random_state=27)\n",
    "svm_sgd.fit(cv_train_features, train_label_names)\n",
    "svmsgd_bow_cv_scores = cross_val_score(svm_sgd, cv_train_features, train_label_names, cv=5)\n",
    "svmsgd_bow_cv_mean_score = np.mean(svmsgd_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svmsgd_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', svmsgd_bow_cv_mean_score)\n",
    "svmsgd_bow_test_score = svm_sgd.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svmsgd_bow_test_score)\n",
    "\n",
    "# CV Accuracy (5-fold): [0.6230441  0.62624822 0.63526053 0.62848962 0.63271162]\n",
    "# Mean CV Accuracy: 0.6291508167210028\n",
    "# Test Accuracy: 0.6573333333333333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.54125178 0.55777461 0.56316916 0.55619184 0.55164993]\n",
      "Mean CV Accuracy: 0.5540074637199572\n",
      "Test Accuracy: 0.5783333333333334\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "rfc = RandomForestClassifier(n_estimators=10, random_state=27)\n",
    "rfc.fit(cv_train_features, train_label_names)\n",
    "rfc_bow_cv_scores = cross_val_score(rfc, cv_train_features, train_label_names, cv=5)\n",
    "rfc_bow_cv_mean_score = np.mean(rfc_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', rfc_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', rfc_bow_cv_mean_score)\n",
    "rfc_bow_test_score = rfc.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', rfc_bow_test_score)\n",
    "\n",
    "# CV Accuracy (5-fold): [0.54125178 0.55777461 0.56316916 0.55619184 0.55164993]\n",
    "# Mean CV Accuracy: 0.5540074637199572\n",
    "# Test Accuracy: 0.5783333333333334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.57539118 0.58844508 0.60599572 0.57480315 0.59397418]\n",
      "Mean CV Accuracy: 0.5877218602201207\n",
      "Test Accuracy: 0.5933333333333334\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "gbc = GradientBoostingClassifier(n_estimators=10, random_state=27)\n",
    "gbc.fit(cv_train_features, train_label_names)\n",
    "gbc_bow_cv_scores = cross_val_score(gbc, cv_train_features, train_label_names, cv=5)\n",
    "gbc_bow_cv_mean_score = np.mean(gbc_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', gbc_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', gbc_bow_cv_mean_score)\n",
    "gbc_bow_test_score = gbc.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', gbc_bow_test_score)\n",
    "\n",
    "# CV Accuracy (5-fold): [0.57539118 0.58844508 0.60599572 0.57480315 0.59397418]\n",
    "# Mean CV Accuracy: 0.5877218602201207\n",
    "# Test Accuracy: 0.5933333333333334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build BOW features on train articles with TFIDF\n",
    "tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0)\n",
    "tv_train_features = tv.fit_transform(train_corpus)\n",
    "\n",
    "# transform test articles into features\n",
    "tv_test_features = tv.transform(test_corpus)\n",
    "\n",
    "# Now I'm going to re-run all of those models with this new set of features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.46443812 0.47289586 0.47965739 0.47244094 0.47704448]\n",
      "Mean CV Accuracy: 0.47329535883498935\n",
      "Test Accuracy: 0.48933333333333334\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1)\n",
    "mnb.fit(tv_train_features, train_label_names)\n",
    "mnb_tfidf_cv_scores = cross_val_score(mnb, tv_train_features, train_label_names, cv=5)\n",
    "mnb_tfidf_cv_mean_score = np.mean(mnb_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', mnb_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', mnb_tfidf_cv_mean_score)\n",
    "mnb_tfidf_test_score = mnb.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', mnb_tfidf_test_score)\n",
    "\n",
    "# CV Accuracy (5-fold): [0.46443812 0.47289586 0.47965739 0.47244094 0.47704448]\n",
    "# Mean CV Accuracy: 0.47329535883498935\n",
    "# Test Accuracy: 0.48933333333333334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.65362731 0.63766049 0.67880086 0.67000716 0.65208034]\n",
      "Mean CV Accuracy: 0.658435231120697\n",
      "Test Accuracy: 0.6763333333333333\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2', max_iter=100, C=1, random_state=27)\n",
    "lr.fit(tv_train_features, train_label_names)\n",
    "lr_tfidf_cv_scores = cross_val_score(lr, tv_train_features, train_label_names, cv=5)\n",
    "lr_tfidf_cv_mean_score = np.mean(lr_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', lr_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', lr_tfidf_cv_mean_score)\n",
    "lr_tfidf_test_score = lr.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', lr_tfidf_test_score)\n",
    "\n",
    "# CV Accuracy (5-fold): [0.65362731 0.63766049 0.67880086 0.67000716 0.65208034]\n",
    "# Mean CV Accuracy: 0.658435231120697\n",
    "# Test Accuracy: 0.6763333333333333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.68349929 0.68045649 0.710207   0.6972083  0.69081779]\n",
      "Mean CV Accuracy: 0.692437773706382\n",
      "Test Accuracy: 0.713\n"
     ]
    }
   ],
   "source": [
    "# Most accurate model now\n",
    "svm = LinearSVC(penalty='l2', C=1, random_state=27)\n",
    "svm.fit(tv_train_features, train_label_names)\n",
    "svm_tfidf_cv_scores = cross_val_score(svm, tv_train_features, train_label_names, cv=5)\n",
    "svm_tfidf_cv_mean_score = np.mean(svm_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svm_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', svm_tfidf_cv_mean_score)\n",
    "svm_tfidf_test_score = svm.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svm_tfidf_test_score)\n",
    "\n",
    "# CV Accuracy (5-fold): [0.68349929 0.68045649 0.710207   0.6972083  0.69081779]\n",
    "# Mean CV Accuracy: 0.692437773706382\n",
    "# Test Accuracy: 0.713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.68634424 0.67831669 0.70663812 0.69219757 0.68794835]\n",
      "Mean CV Accuracy: 0.6902889922669571\n",
      "Test Accuracy: 0.709\n"
     ]
    }
   ],
   "source": [
    "# Second most accurate model now\n",
    "svm_sgd = SGDClassifier(loss='hinge', penalty='l2', max_iter=5, random_state=27)\n",
    "svm_sgd.fit(tv_train_features, train_label_names)\n",
    "svmsgd_tfidf_cv_scores = cross_val_score(svm_sgd, tv_train_features, train_label_names, cv=5)\n",
    "svmsgd_tfidf_cv_mean_score = np.mean(svmsgd_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svmsgd_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', svmsgd_tfidf_cv_mean_score)\n",
    "svmsgd_tfidf_test_score = svm_sgd.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svmsgd_tfidf_test_score)\n",
    "\n",
    "# CV Accuracy (5-fold): [0.68634424 0.67831669 0.70663812 0.69219757 0.68794835]\n",
    "# Mean CV Accuracy: 0.6902889922669571\n",
    "# Test Accuracy: 0.709"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.52987198 0.53851641 0.57744468 0.54903364 0.56169297]\n",
      "Mean CV Accuracy: 0.5513119356276726\n",
      "Test Accuracy: 0.582\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10, random_state=27)\n",
    "rfc.fit(tv_train_features, train_label_names)\n",
    "rfc_tfidf_cv_scores = cross_val_score(rfc, tv_train_features, train_label_names, cv=5)\n",
    "rfc_tfidf_cv_mean_score = np.mean(rfc_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', rfc_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', rfc_tfidf_cv_mean_score)\n",
    "rfc_tfidf_test_score = rfc.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', rfc_tfidf_test_score)\n",
    "\n",
    "# CV Accuracy (5-fold): [0.52987198 0.53851641 0.57744468 0.54903364 0.56169297]\n",
    "# Mean CV Accuracy: 0.5513119356276726\n",
    "# Test Accuracy: 0.582"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.58534851 0.58202568 0.59814418 0.57766643 0.58106169]\n",
      "Mean CV Accuracy: 0.584849297552237\n",
      "Test Accuracy: 0.5943333333333334\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=10, random_state=27 )\n",
    "gbc.fit(tv_train_features, train_label_names)\n",
    "gbc_tfidf_cv_scores = cross_val_score(gbc, tv_train_features, train_label_names, cv=5)\n",
    "gbc_tfidf_cv_mean_score = np.mean(gbc_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', gbc_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', gbc_tfidf_cv_mean_score)\n",
    "gbc_tfidf_test_score = gbc.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', gbc_tfidf_test_score)\n",
    "\n",
    "# CV Accuracy (5-fold): [0.58534851 0.58202568 0.59814418 0.57766643 0.58106169]\n",
    "# Mean CV Accuracy: 0.584849297552237\n",
    "# Test Accuracy: 0.5943333333333334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>Linear SVM (SGD)</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Gradient Boosted Machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV Score (TF)</th>\n",
       "      <td>0.612717</td>\n",
       "      <td>0.690731</td>\n",
       "      <td>0.63946</td>\n",
       "      <td>0.629151</td>\n",
       "      <td>0.554007</td>\n",
       "      <td>0.587722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Score (TF)</th>\n",
       "      <td>0.629333</td>\n",
       "      <td>0.704333</td>\n",
       "      <td>0.653667</td>\n",
       "      <td>0.657333</td>\n",
       "      <td>0.578333</td>\n",
       "      <td>0.593333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV Score (TF-IDF)</th>\n",
       "      <td>0.473295</td>\n",
       "      <td>0.658435</td>\n",
       "      <td>0.692438</td>\n",
       "      <td>0.690289</td>\n",
       "      <td>0.551312</td>\n",
       "      <td>0.584849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Score (TF-IDF)</th>\n",
       "      <td>0.489333</td>\n",
       "      <td>0.676333</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.594333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0                    1           2  \\\n",
       "Model                Naive Bayes  Logistic Regression  Linear SVM   \n",
       "CV Score (TF)           0.612717             0.690731     0.63946   \n",
       "Test Score (TF)         0.629333             0.704333    0.653667   \n",
       "CV Score (TF-IDF)       0.473295             0.658435    0.692438   \n",
       "Test Score (TF-IDF)     0.489333             0.676333       0.713   \n",
       "\n",
       "                                    3              4  \\\n",
       "Model                Linear SVM (SGD)  Random Forest   \n",
       "CV Score (TF)                0.629151       0.554007   \n",
       "Test Score (TF)              0.657333       0.578333   \n",
       "CV Score (TF-IDF)            0.690289       0.551312   \n",
       "Test Score (TF-IDF)             0.709          0.582   \n",
       "\n",
       "                                             5  \n",
       "Model                Gradient Boosted Machines  \n",
       "CV Score (TF)                         0.587722  \n",
       "Test Score (TF)                       0.593333  \n",
       "CV Score (TF-IDF)                     0.584849  \n",
       "Test Score (TF-IDF)                   0.594333  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a pretty table of all the results\n",
    "pd.DataFrame([['Naive Bayes', mnb_bow_cv_mean_score, mnb_bow_test_score, \n",
    "               mnb_tfidf_cv_mean_score, mnb_tfidf_test_score],\n",
    "              ['Logistic Regression', lr_bow_cv_mean_score, lr_bow_test_score, \n",
    "               lr_tfidf_cv_mean_score, lr_tfidf_test_score],\n",
    "              ['Linear SVM', svm_bow_cv_mean_score, svm_bow_test_score, \n",
    "               svm_tfidf_cv_mean_score, svm_tfidf_test_score],\n",
    "              ['Linear SVM (SGD)', svmsgd_bow_cv_mean_score, svmsgd_bow_test_score, \n",
    "               svmsgd_tfidf_cv_mean_score, svmsgd_tfidf_test_score],\n",
    "              ['Random Forest', rfc_bow_cv_mean_score, rfc_bow_test_score, \n",
    "               rfc_tfidf_cv_mean_score, rfc_tfidf_test_score],\n",
    "              ['Gradient Boosted Machines', gbc_bow_cv_mean_score, gbc_bow_test_score, \n",
    "               gbc_tfidf_cv_mean_score, gbc_tfidf_test_score]],\n",
    "             columns=['Model', 'CV Score (TF)', 'Test Score (TF)', 'CV Score (TF-IDF)', 'Test Score (TF-IDF)'],\n",
    "             ).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] svm__C=0.01, tfidf__ngram_range=(1, 1) ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... svm__C=0.01, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] svm__C=0.01, tfidf__ngram_range=(1, 1) ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... svm__C=0.01, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] svm__C=0.01, tfidf__ngram_range=(1, 1) ..........................\n",
      "[CV] ........... svm__C=0.01, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] svm__C=0.01, tfidf__ngram_range=(1, 1) ..........................\n",
      "[CV] ........... svm__C=0.01, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] svm__C=0.01, tfidf__ngram_range=(1, 1) ..........................\n",
      "[CV] ........... svm__C=0.01, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] svm__C=0.01, tfidf__ngram_range=(1, 2) ..........................\n",
      "[CV] ........... svm__C=0.01, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] svm__C=0.01, tfidf__ngram_range=(1, 2) ..........................\n",
      "[CV] ........... svm__C=0.01, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] svm__C=0.01, tfidf__ngram_range=(1, 2) ..........................\n",
      "[CV] ........... svm__C=0.01, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] svm__C=0.01, tfidf__ngram_range=(1, 2) ..........................\n",
      "[CV] ........... svm__C=0.01, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] svm__C=0.01, tfidf__ngram_range=(1, 2) ..........................\n",
      "[CV] ........... svm__C=0.01, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] svm__C=0.1, tfidf__ngram_range=(1, 1) ...........................\n",
      "[CV] ............ svm__C=0.1, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] svm__C=0.1, tfidf__ngram_range=(1, 1) ...........................\n",
      "[CV] ............ svm__C=0.1, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] svm__C=0.1, tfidf__ngram_range=(1, 1) ...........................\n",
      "[CV] ............ svm__C=0.1, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] svm__C=0.1, tfidf__ngram_range=(1, 1) ...........................\n",
      "[CV] ............ svm__C=0.1, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] svm__C=0.1, tfidf__ngram_range=(1, 1) ...........................\n",
      "[CV] ............ svm__C=0.1, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] svm__C=0.1, tfidf__ngram_range=(1, 2) ...........................\n",
      "[CV] ............ svm__C=0.1, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] svm__C=0.1, tfidf__ngram_range=(1, 2) ...........................\n",
      "[CV] ............ svm__C=0.1, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] svm__C=0.1, tfidf__ngram_range=(1, 2) ...........................\n",
      "[CV] ............ svm__C=0.1, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] svm__C=0.1, tfidf__ngram_range=(1, 2) ...........................\n",
      "[CV] ............ svm__C=0.1, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] svm__C=0.1, tfidf__ngram_range=(1, 2) ...........................\n",
      "[CV] ............ svm__C=0.1, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] svm__C=1, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. svm__C=1, tfidf__ngram_range=(1, 1), total=   0.4s\n",
      "[CV] svm__C=1, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. svm__C=1, tfidf__ngram_range=(1, 1), total=   0.3s\n",
      "[CV] svm__C=1, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. svm__C=1, tfidf__ngram_range=(1, 1), total=   0.3s\n",
      "[CV] svm__C=1, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. svm__C=1, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] svm__C=1, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. svm__C=1, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] svm__C=1, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. svm__C=1, tfidf__ngram_range=(1, 2), total=   0.7s\n",
      "[CV] svm__C=1, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. svm__C=1, tfidf__ngram_range=(1, 2), total=   0.7s\n",
      "[CV] svm__C=1, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. svm__C=1, tfidf__ngram_range=(1, 2), total=   0.7s\n",
      "[CV] svm__C=1, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. svm__C=1, tfidf__ngram_range=(1, 2), total=   0.8s\n",
      "[CV] svm__C=1, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. svm__C=1, tfidf__ngram_range=(1, 2), total=   0.8s\n",
      "[CV] svm__C=5, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. svm__C=5, tfidf__ngram_range=(1, 1), total=   0.4s\n",
      "[CV] svm__C=5, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. svm__C=5, tfidf__ngram_range=(1, 1), total=   0.4s\n",
      "[CV] svm__C=5, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. svm__C=5, tfidf__ngram_range=(1, 1), total=   0.4s\n",
      "[CV] svm__C=5, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. svm__C=5, tfidf__ngram_range=(1, 1), total=   0.4s\n",
      "[CV] svm__C=5, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. svm__C=5, tfidf__ngram_range=(1, 1), total=   0.4s\n",
      "[CV] svm__C=5, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. svm__C=5, tfidf__ngram_range=(1, 2), total=   1.1s\n",
      "[CV] svm__C=5, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. svm__C=5, tfidf__ngram_range=(1, 2), total=   1.1s\n",
      "[CV] svm__C=5, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. svm__C=5, tfidf__ngram_range=(1, 2), total=   1.1s\n",
      "[CV] svm__C=5, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. svm__C=5, tfidf__ngram_range=(1, 2), total=   1.0s\n",
      "[CV] svm__C=5, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. svm__C=5, tfidf__ngram_range=(1, 2), total=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:   27.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Fiddling with parameters of LinearSVM\n",
    "svm_pipeline = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('svm', LinearSVC(random_state=27))\n",
    "                       ])\n",
    "\n",
    "param_grid = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "              'svm__C': [0.01, 0.1, 1, 5]\n",
    "}\n",
    "\n",
    "gs_svm = GridSearchCV(svm_pipeline, param_grid, cv=5, verbose=2)\n",
    "gs_svm = gs_svm.fit(train_corpus, train_label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('tfidf',\n",
       "   TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "           stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "           token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "           vocabulary=None)),\n",
       "  ('svm', LinearSVC(C=5, class_weight=None, dual=True, fit_intercept=True,\n",
       "        intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "        multi_class='ovr', penalty='l2', random_state=27, tol=0.0001,\n",
       "        verbose=0))],\n",
       " 'tfidf': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "         stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "         token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "         vocabulary=None),\n",
       " 'svm': LinearSVC(C=5, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=27, tol=0.0001,\n",
       "      verbose=0),\n",
       " 'tfidf__analyzer': 'word',\n",
       " 'tfidf__binary': False,\n",
       " 'tfidf__decode_error': 'strict',\n",
       " 'tfidf__dtype': numpy.float64,\n",
       " 'tfidf__encoding': 'utf-8',\n",
       " 'tfidf__input': 'content',\n",
       " 'tfidf__lowercase': True,\n",
       " 'tfidf__max_df': 1.0,\n",
       " 'tfidf__max_features': None,\n",
       " 'tfidf__min_df': 1,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__preprocessor': None,\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__stop_words': None,\n",
       " 'tfidf__strip_accents': None,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tfidf__tokenizer': None,\n",
       " 'tfidf__use_idf': True,\n",
       " 'tfidf__vocabulary': None,\n",
       " 'svm__C': 5,\n",
       " 'svm__class_weight': None,\n",
       " 'svm__dual': True,\n",
       " 'svm__fit_intercept': True,\n",
       " 'svm__intercept_scaling': 1,\n",
       " 'svm__loss': 'squared_hinge',\n",
       " 'svm__max_iter': 1000,\n",
       " 'svm__multi_class': 'ovr',\n",
       " 'svm__penalty': 'l2',\n",
       " 'svm__random_state': 27,\n",
       " 'svm__tol': 0.0001,\n",
       " 'svm__verbose': 0}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svm.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.718\n"
     ]
    }
   ],
   "source": [
    "# Now this model is the most accurate\n",
    "best_svm_test_score = gs_svm.score(test_corpus, test_label_names)\n",
    "print('Test Accuracy :', best_svm_test_score)\n",
    "\n",
    "# Test Accuracy : 0.718, slightly improved by 0.02 with combined categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.718\n",
      "Precision: 0.7248\n",
      "Recall: 0.718\n",
      "F1 Score: 0.7084\n"
     ]
    }
   ],
   "source": [
    "svm_predictions = gs_svm.predict(test_corpus)\n",
    "unique_classes = list(set(test_label_names))\n",
    "meu.get_metrics(true_labels=test_label_names, predicted_labels=svm_predictions)\n",
    "\n",
    "# Accuracy: 0.718\n",
    "# Precision: 0.7248\n",
    "# Recall: 0.718\n",
    "# F1 Score: 0.7084"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        Chardonnay       0.75      0.91      0.82       480\n",
      "   Sauvignon Blanc       0.77      0.72      0.75       191\n",
      "       Mo/uscat(o)       1.00      0.32      0.48        25\n",
      "       White Blend       0.81      0.47      0.60        91\n",
      "              Rose       0.77      0.71      0.74       141\n",
      "            Shiraz       0.71      0.38      0.50        26\n",
      "         Zinfandel       0.55      0.38      0.45        96\n",
      "            Malbec       0.59      0.45      0.51       113\n",
      "            Merlot       0.80      0.38      0.51       104\n",
      "         Red Blend       0.79      0.72      0.75       368\n",
      "        Pinot Noir       0.69      0.88      0.77       517\n",
      "          Riesling       0.79      0.81      0.80       198\n",
      " Pinot Gris/Grigio       0.87      0.49      0.63        96\n",
      "Cabernet Sauvignon       0.61      0.72      0.66       361\n",
      "             Syrah       0.69      0.54      0.61       193\n",
      "\n",
      "         micro avg       0.72      0.72      0.72      3000\n",
      "         macro avg       0.75      0.59      0.64      3000\n",
      "      weighted avg       0.72      0.72      0.71      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meu.display_classification_report(true_labels=test_label_names, \n",
    "                                  predicted_labels=svm_predictions, classes=unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
