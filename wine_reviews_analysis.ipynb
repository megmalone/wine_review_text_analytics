{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import csv\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import model_evaluation_utils as meu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset (already have isolated the two columns for this analysis)\n",
    "wine = pd.read_csv('winemag_filt.csv')\n",
    "\n",
    "# Filter for 15 most popular wine varieties in the US\n",
    "top15 = ['Pinot Noir','Chardonnay','Cabernet Sauvignon',\n",
    "         'Red Blend','Riesling','Sauvignon Blanc','Syrah',\n",
    "         'Rose','Merlot','Zinfandel','Malbec', 'White Blend',\n",
    "        'Pinot Gris','Pinot Grigio','Shiraz','Moscato', 'Muscat']\n",
    "\n",
    "wine = wine[wine.variety.isin(top15)]\n",
    "\n",
    "# Take a random sample of 10000 observations from that filtered set\n",
    "wine_samp = wine.sample(n=10000, random_state=27)\n",
    "\n",
    "# Format columns as lists\n",
    "corpus = wine_samp['description'].values.tolist()\n",
    "labels = wine_samp['variety'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accented char function\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special char function\n",
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', parse=True, tag=True, entity=True)\n",
    "\n",
    "# Lemmatization function (version of stemming that maintains English spellings)\n",
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer function\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "def remove_stopwords(text, is_lower_case=False, stopwords=stopword_list):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopwords]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the functions together now!\n",
    "def normalize_corpus(corpus,\n",
    "                     accented_char_removal=True, text_lower_case=True, \n",
    "                     text_lemmatization=True, special_char_removal=True, \n",
    "                     stopword_removal=True, remove_digits=True):\n",
    "    \n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "        # remove accented characters\n",
    "        if accented_char_removal:\n",
    "            doc = remove_accented_chars(doc)\n",
    "        # lowercase the text    \n",
    "        if text_lower_case:\n",
    "            doc = doc.lower()\n",
    "        # remove extra newlines\n",
    "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
    "        # lemmatize text\n",
    "        if text_lemmatization:\n",
    "            doc = lemmatize_text(doc)\n",
    "        # remove special characters and\\or digits    \n",
    "        if special_char_removal:\n",
    "            # insert spaces between special characters to isolate them    \n",
    "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "            doc = remove_special_characters(doc, remove_digits=remove_digits)  \n",
    "        # remove extra whitespace\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        # remove stopwords\n",
    "        if stopword_removal:\n",
    "            doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
    "            \n",
    "        normalized_corpus.append(doc)\n",
    "        \n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying to the data\n",
    "norm_corpus = normalize_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making training and test sets\n",
    "train_corpus, test_corpus, train_label_names, test_label_names = train_test_split(norm_corpus, labels, test_size=0.3, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Train Count</th>\n",
       "      <th>Test Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>1267</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>1083</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>870</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red Blend</td>\n",
       "      <td>803</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Riesling</td>\n",
       "      <td>456</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>440</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Syrah</td>\n",
       "      <td>389</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rose</td>\n",
       "      <td>329</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Merlot</td>\n",
       "      <td>280</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Zinfandel</td>\n",
       "      <td>273</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Malbec</td>\n",
       "      <td>234</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>White Blend</td>\n",
       "      <td>221</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>129</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pinot Grigio</td>\n",
       "      <td>99</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shiraz</td>\n",
       "      <td>91</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Moscato</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Muscat</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Target Label  Train Count  Test Count\n",
       "3           Pinot Noir         1267         517\n",
       "0           Chardonnay         1083         480\n",
       "8   Cabernet Sauvignon          870         361\n",
       "1            Red Blend          803         368\n",
       "6             Riesling          456         198\n",
       "4      Sauvignon Blanc          440         191\n",
       "7                Syrah          389         193\n",
       "2                 Rose          329         141\n",
       "13              Merlot          280         104\n",
       "5            Zinfandel          273          96\n",
       "10              Malbec          234         113\n",
       "12         White Blend          221          91\n",
       "14          Pinot Gris          129          60\n",
       "9         Pinot Grigio           99          36\n",
       "11              Shiraz           91          26\n",
       "15             Moscato           26          18\n",
       "16              Muscat           10           7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table of distribution of varities in test, training datasets\n",
    "trd = dict(Counter(train_label_names))\n",
    "tsd = dict(Counter(test_label_names))\n",
    "\n",
    "(pd.DataFrame([[key, trd[key], tsd[key]] for key in trd], \n",
    "             columns=['Target Label', 'Train Count', 'Test Count'])\n",
    ".sort_values(by=['Train Count', 'Test Count'],\n",
    "             ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build Bag of Words features on train articles\n",
    "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0)\n",
    "cv_train_features = cv.fit_transform(train_corpus)\n",
    "\n",
    "# transform test articles into features\n",
    "cv_test_features = cv.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.6059744  0.60271041 0.6152748  0.62517883 0.60086145]\n",
      "Mean CV Accuracy: 0.6099999779715365\n",
      "Test Accuracy: 0.624\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes model!\n",
    "mnb = MultinomialNB(alpha=1)\n",
    "mnb.fit(cv_train_features, train_label_names)\n",
    "mnb_bow_cv_scores = cross_val_score(mnb, cv_train_features, train_label_names, cv=5)\n",
    "mnb_bow_cv_mean_score = np.mean(mnb_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', mnb_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', mnb_bow_cv_mean_score)\n",
    "mnb_bow_test_score = mnb.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', mnb_bow_test_score)\n",
    "\n",
    "# CV Accuracy (5-fold): [0.6059744  0.60271041 0.6152748  0.62517883 0.60086145]\n",
    "# Mean CV Accuracy: 0.6099999779715365\n",
    "# Test Accuracy: 0.624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.67923186 0.68972896 0.70164168 0.68383405 0.70136396]\n",
      "Mean CV Accuracy: 0.6911601035790784\n",
      "Test Accuracy: 0.704\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model!\n",
    "lr = LogisticRegression(penalty='l2', max_iter=100, C=1, random_state=27)\n",
    "lr.fit(cv_train_features, train_label_names)\n",
    "lr_bow_cv_scores = cross_val_score(lr, cv_train_features, train_label_names, cv=5)\n",
    "lr_bow_cv_mean_score = np.mean(lr_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', lr_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', lr_bow_cv_mean_score)\n",
    "lr_bow_test_score = lr.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', lr_bow_test_score)\n",
    "\n",
    "# CV Accuracy (5-fold): [0.67923186 0.68972896 0.70164168 0.68383405 0.70136396]\n",
    "# Mean CV Accuracy: 0.6911601035790784\n",
    "# Test Accuracy: 0.704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.61806543 0.64051355 0.65167737 0.62947067 0.65613783]\n",
      "Mean CV Accuracy: 0.639172972726904\n",
      "Test Accuracy: 0.6533333333333333\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC model!\n",
    "svm = LinearSVC(penalty='l2', C=1, random_state=27)\n",
    "svm.fit(cv_train_features, train_label_names)\n",
    "svm_bow_cv_scores = cross_val_score(svm, cv_train_features, train_label_names, cv=5)\n",
    "svm_bow_cv_mean_score = np.mean(svm_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svm_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', svm_bow_cv_mean_score)\n",
    "svm_bow_test_score = svm.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svm_bow_test_score)\n",
    "\n",
    "# CV Accuracy (5-fold): [0.61806543 0.64051355 0.65167737 0.62947067 0.65613783]\n",
    "# Mean CV Accuracy: 0.639172972726904\n",
    "# Test Accuracy: 0.6533333333333333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.61379801 0.64051355 0.6359743  0.6316166  0.64393396]\n",
      "Mean CV Accuracy: 0.6331672830598999\n",
      "Test Accuracy: 0.6723333333333333\n"
     ]
    }
   ],
   "source": [
    "# SDGClassifier!\n",
    "svm_sgd = SGDClassifier(loss='hinge', penalty='l2', max_iter=5, random_state=27)\n",
    "svm_sgd.fit(cv_train_features, train_label_names)\n",
    "svmsgd_bow_cv_scores = cross_val_score(svm_sgd, cv_train_features, train_label_names, cv=5)\n",
    "svmsgd_bow_cv_mean_score = np.mean(svmsgd_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svmsgd_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', svmsgd_bow_cv_mean_score)\n",
    "svmsgd_bow_test_score = svm_sgd.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svmsgd_bow_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.53769559 0.56847361 0.55817273 0.57081545 0.55994257]\n",
      "Mean CV Accuracy: 0.5590199907710363\n",
      "Test Accuracy: 0.5706666666666667\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "rfc = RandomForestClassifier(n_estimators=10, random_state=27)\n",
    "rfc.fit(cv_train_features, train_label_names)\n",
    "rfc_bow_cv_scores = cross_val_score(rfc, cv_train_features, train_label_names, cv=5)\n",
    "rfc_bow_cv_mean_score = np.mean(rfc_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', rfc_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', rfc_bow_cv_mean_score)\n",
    "rfc_bow_test_score = rfc.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', rfc_bow_test_score)\n",
    "\n",
    "# CV Accuracy (5-fold): [0.53769559 0.56847361 0.55817273 0.57081545 0.55994257]\n",
    "# Mean CV Accuracy: 0.5590199907710363\n",
    "# Test Accuracy: 0.5706666666666667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.58392603 0.59201141 0.61456103 0.5758226  0.5965542 ]\n",
      "Mean CV Accuracy: 0.5925750549377549\n",
      "Test Accuracy: 0.5923333333333334\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "gbc = GradientBoostingClassifier(n_estimators=10, random_state=27)\n",
    "gbc.fit(cv_train_features, train_label_names)\n",
    "gbc_bow_cv_scores = cross_val_score(gbc, cv_train_features, train_label_names, cv=5)\n",
    "gbc_bow_cv_mean_score = np.mean(gbc_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', gbc_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', gbc_bow_cv_mean_score)\n",
    "gbc_bow_test_score = gbc.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', gbc_bow_test_score)\n",
    "\n",
    "# CV Accuracy (5-fold): [0.58392603 0.59201141 0.61456103 0.5758226  0.5965542 ]\n",
    "# Mean CV Accuracy: 0.5925750549377549\n",
    "# Test Accuracy: 0.5923333333333334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build BOW features on train articles with TFIDF\n",
    "tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0)\n",
    "tv_train_features = tv.fit_transform(train_corpus)\n",
    "\n",
    "# transform test articles into features\n",
    "tv_test_features = tv.transform(test_corpus)\n",
    "\n",
    "# Now I'm going to re-run all of those models with this new set of features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.46443812 0.47289586 0.47965739 0.472103   0.47738693]\n",
      "Mean CV Accuracy: 0.4732962623862306\n",
      "Test Accuracy: 0.48933333333333334\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1)\n",
    "mnb.fit(tv_train_features, train_label_names)\n",
    "mnb_tfidf_cv_scores = cross_val_score(mnb, tv_train_features, train_label_names, cv=5)\n",
    "mnb_tfidf_cv_mean_score = np.mean(mnb_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', mnb_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', mnb_tfidf_cv_mean_score)\n",
    "mnb_tfidf_test_score = mnb.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', mnb_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.6514936  0.63623395 0.67594575 0.66595136 0.64895908]\n",
      "Mean CV Accuracy: 0.6557167487195439\n",
      "Test Accuracy: 0.672\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2', max_iter=100, C=1, random_state=27)\n",
    "lr.fit(tv_train_features, train_label_names)\n",
    "lr_tfidf_cv_scores = cross_val_score(lr, tv_train_features, train_label_names, cv=5)\n",
    "lr_tfidf_cv_mean_score = np.mean(lr_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', lr_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', lr_tfidf_cv_mean_score)\n",
    "lr_tfidf_test_score = lr.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', lr_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.67923186 0.68045649 0.70877944 0.69599428 0.68772434]\n",
      "Mean CV Accuracy: 0.6904372821859247\n",
      "Test Accuracy: 0.7126666666666667\n"
     ]
    }
   ],
   "source": [
    "# Second most accurate model\n",
    "svm = LinearSVC(penalty='l2', C=1, random_state=27)\n",
    "svm.fit(tv_train_features, train_label_names)\n",
    "svm_tfidf_cv_scores = cross_val_score(svm, tv_train_features, train_label_names, cv=5)\n",
    "svm_tfidf_cv_mean_score = np.mean(svm_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svm_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', svm_tfidf_cv_mean_score)\n",
    "svm_tfidf_test_score = svm.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svm_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.68278805 0.68616262 0.71734475 0.69027182 0.68269921]\n",
      "Mean CV Accuracy: 0.6918532913993541\n",
      "Test Accuracy: 0.7136666666666667\n"
     ]
    }
   ],
   "source": [
    "# Returns the most accurate model\n",
    "svm_sgd = SGDClassifier(loss='hinge', penalty='l2', max_iter=5, random_state=27)\n",
    "svm_sgd.fit(tv_train_features, train_label_names)\n",
    "svmsgd_tfidf_cv_scores = cross_val_score(svm_sgd, tv_train_features, train_label_names, cv=5)\n",
    "svmsgd_tfidf_cv_mean_score = np.mean(svmsgd_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svmsgd_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', svmsgd_tfidf_cv_mean_score)\n",
    "svmsgd_tfidf_test_score = svm_sgd.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svmsgd_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.54623044 0.54564907 0.57316203 0.5658083  0.55348169]\n",
      "Mean CV Accuracy: 0.5568663065194284\n",
      "Test Accuracy: 0.545\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10, random_state=27)\n",
    "rfc.fit(tv_train_features, train_label_names)\n",
    "rfc_tfidf_cv_scores = cross_val_score(rfc, tv_train_features, train_label_names, cv=5)\n",
    "rfc_tfidf_cv_mean_score = np.mean(rfc_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', rfc_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', rfc_tfidf_cv_mean_score)\n",
    "rfc_tfidf_test_score = rfc.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', rfc_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.57041252 0.58701854 0.60314061 0.57653791 0.58650395]\n",
      "Mean CV Accuracy: 0.5847227072357699\n",
      "Test Accuracy: 0.598\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=10, random_state=27 )\n",
    "gbc.fit(tv_train_features, train_label_names)\n",
    "gbc_tfidf_cv_scores = cross_val_score(gbc, tv_train_features, train_label_names, cv=5)\n",
    "gbc_tfidf_cv_mean_score = np.mean(gbc_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', gbc_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', gbc_tfidf_cv_mean_score)\n",
    "gbc_tfidf_test_score = gbc.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', gbc_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>Linear SVM (SGD)</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Gradient Boosted Machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV Score (TF)</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.69116</td>\n",
       "      <td>0.639173</td>\n",
       "      <td>0.633167</td>\n",
       "      <td>0.55902</td>\n",
       "      <td>0.592575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Score (TF)</th>\n",
       "      <td>0.624</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.672333</td>\n",
       "      <td>0.570667</td>\n",
       "      <td>0.592333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV Score (TF-IDF)</th>\n",
       "      <td>0.473296</td>\n",
       "      <td>0.655717</td>\n",
       "      <td>0.690437</td>\n",
       "      <td>0.691853</td>\n",
       "      <td>0.556866</td>\n",
       "      <td>0.584723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Score (TF-IDF)</th>\n",
       "      <td>0.489333</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.712667</td>\n",
       "      <td>0.713667</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0                    1           2  \\\n",
       "Model                Naive Bayes  Logistic Regression  Linear SVM   \n",
       "CV Score (TF)               0.61              0.69116    0.639173   \n",
       "Test Score (TF)            0.624                0.704    0.653333   \n",
       "CV Score (TF-IDF)       0.473296             0.655717    0.690437   \n",
       "Test Score (TF-IDF)     0.489333                0.672    0.712667   \n",
       "\n",
       "                                    3              4  \\\n",
       "Model                Linear SVM (SGD)  Random Forest   \n",
       "CV Score (TF)                0.633167        0.55902   \n",
       "Test Score (TF)              0.672333       0.570667   \n",
       "CV Score (TF-IDF)            0.691853       0.556866   \n",
       "Test Score (TF-IDF)          0.713667          0.545   \n",
       "\n",
       "                                             5  \n",
       "Model                Gradient Boosted Machines  \n",
       "CV Score (TF)                         0.592575  \n",
       "Test Score (TF)                       0.592333  \n",
       "CV Score (TF-IDF)                     0.584723  \n",
       "Test Score (TF-IDF)                      0.598  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a pretty table of all the results\n",
    "pd.DataFrame([['Naive Bayes', mnb_bow_cv_mean_score, mnb_bow_test_score, \n",
    "               mnb_tfidf_cv_mean_score, mnb_tfidf_test_score],\n",
    "              ['Logistic Regression', lr_bow_cv_mean_score, lr_bow_test_score, \n",
    "               lr_tfidf_cv_mean_score, lr_tfidf_test_score],\n",
    "              ['Linear SVM', svm_bow_cv_mean_score, svm_bow_test_score, \n",
    "               svm_tfidf_cv_mean_score, svm_tfidf_test_score],\n",
    "              ['Linear SVM (SGD)', svmsgd_bow_cv_mean_score, svmsgd_bow_test_score, \n",
    "               svmsgd_tfidf_cv_mean_score, svmsgd_tfidf_test_score],\n",
    "              ['Random Forest', rfc_bow_cv_mean_score, rfc_bow_test_score, \n",
    "               rfc_tfidf_cv_mean_score, rfc_tfidf_test_score],\n",
    "              ['Gradient Boosted Machines', gbc_bow_cv_mean_score, gbc_bow_test_score, \n",
    "               gbc_tfidf_cv_mean_score, gbc_tfidf_test_score]],\n",
    "             columns=['Model', 'CV Score (TF)', 'Test Score (TF)', 'CV Score (TF-IDF)', 'Test Score (TF-IDF)'],\n",
    "             ).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] sgd__alpha=1e-07, tfidf__ngram_range=(1, 1) .....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... sgd__alpha=1e-07, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] sgd__alpha=1e-07, tfidf__ngram_range=(1, 1) .....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... sgd__alpha=1e-07, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] sgd__alpha=1e-07, tfidf__ngram_range=(1, 1) .....................\n",
      "[CV] ...... sgd__alpha=1e-07, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] sgd__alpha=1e-07, tfidf__ngram_range=(1, 1) .....................\n",
      "[CV] ...... sgd__alpha=1e-07, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] sgd__alpha=1e-07, tfidf__ngram_range=(1, 1) .....................\n",
      "[CV] ...... sgd__alpha=1e-07, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] sgd__alpha=1e-07, tfidf__ngram_range=(1, 2) .....................\n",
      "[CV] ...... sgd__alpha=1e-07, tfidf__ngram_range=(1, 2), total=   0.5s\n",
      "[CV] sgd__alpha=1e-07, tfidf__ngram_range=(1, 2) .....................\n",
      "[CV] ...... sgd__alpha=1e-07, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] sgd__alpha=1e-07, tfidf__ngram_range=(1, 2) .....................\n",
      "[CV] ...... sgd__alpha=1e-07, tfidf__ngram_range=(1, 2), total=   0.5s\n",
      "[CV] sgd__alpha=1e-07, tfidf__ngram_range=(1, 2) .....................\n",
      "[CV] ...... sgd__alpha=1e-07, tfidf__ngram_range=(1, 2), total=   0.5s\n",
      "[CV] sgd__alpha=1e-07, tfidf__ngram_range=(1, 2) .....................\n",
      "[CV] ...... sgd__alpha=1e-07, tfidf__ngram_range=(1, 2), total=   0.5s\n",
      "[CV] sgd__alpha=1e-06, tfidf__ngram_range=(1, 1) .....................\n",
      "[CV] ...... sgd__alpha=1e-06, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] sgd__alpha=1e-06, tfidf__ngram_range=(1, 1) .....................\n",
      "[CV] ...... sgd__alpha=1e-06, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] sgd__alpha=1e-06, tfidf__ngram_range=(1, 1) .....................\n",
      "[CV] ...... sgd__alpha=1e-06, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] sgd__alpha=1e-06, tfidf__ngram_range=(1, 1) .....................\n",
      "[CV] ...... sgd__alpha=1e-06, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] sgd__alpha=1e-06, tfidf__ngram_range=(1, 1) .....................\n",
      "[CV] ...... sgd__alpha=1e-06, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] sgd__alpha=1e-06, tfidf__ngram_range=(1, 2) .....................\n",
      "[CV] ...... sgd__alpha=1e-06, tfidf__ngram_range=(1, 2), total=   0.5s\n",
      "[CV] sgd__alpha=1e-06, tfidf__ngram_range=(1, 2) .....................\n",
      "[CV] ...... sgd__alpha=1e-06, tfidf__ngram_range=(1, 2), total=   0.5s\n",
      "[CV] sgd__alpha=1e-06, tfidf__ngram_range=(1, 2) .....................\n",
      "[CV] ...... sgd__alpha=1e-06, tfidf__ngram_range=(1, 2), total=   0.5s\n",
      "[CV] sgd__alpha=1e-06, tfidf__ngram_range=(1, 2) .....................\n",
      "[CV] ...... sgd__alpha=1e-06, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] sgd__alpha=1e-06, tfidf__ngram_range=(1, 2) .....................\n",
      "[CV] ...... sgd__alpha=1e-06, tfidf__ngram_range=(1, 2), total=   0.5s\n",
      "[CV] sgd__alpha=1e-05, tfidf__ngram_range=(1, 1) .....................\n",
      "[CV] ...... sgd__alpha=1e-05, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] sgd__alpha=1e-05, tfidf__ngram_range=(1, 1) .....................\n",
      "[CV] ...... sgd__alpha=1e-05, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] sgd__alpha=1e-05, tfidf__ngram_range=(1, 1) .....................\n",
      "[CV] ...... sgd__alpha=1e-05, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] sgd__alpha=1e-05, tfidf__ngram_range=(1, 1) .....................\n",
      "[CV] ...... sgd__alpha=1e-05, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] sgd__alpha=1e-05, tfidf__ngram_range=(1, 1) .....................\n",
      "[CV] ...... sgd__alpha=1e-05, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] sgd__alpha=1e-05, tfidf__ngram_range=(1, 2) .....................\n",
      "[CV] ...... sgd__alpha=1e-05, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] sgd__alpha=1e-05, tfidf__ngram_range=(1, 2) .....................\n",
      "[CV] ...... sgd__alpha=1e-05, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] sgd__alpha=1e-05, tfidf__ngram_range=(1, 2) .....................\n",
      "[CV] ...... sgd__alpha=1e-05, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] sgd__alpha=1e-05, tfidf__ngram_range=(1, 2) .....................\n",
      "[CV] ...... sgd__alpha=1e-05, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] sgd__alpha=1e-05, tfidf__ngram_range=(1, 2) .....................\n",
      "[CV] ...... sgd__alpha=1e-05, tfidf__ngram_range=(1, 2), total=   0.5s\n",
      "[CV] sgd__alpha=0.0001, tfidf__ngram_range=(1, 1) ....................\n",
      "[CV] ..... sgd__alpha=0.0001, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] sgd__alpha=0.0001, tfidf__ngram_range=(1, 1) ....................\n",
      "[CV] ..... sgd__alpha=0.0001, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] sgd__alpha=0.0001, tfidf__ngram_range=(1, 1) ....................\n",
      "[CV] ..... sgd__alpha=0.0001, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] sgd__alpha=0.0001, tfidf__ngram_range=(1, 1) ....................\n",
      "[CV] ..... sgd__alpha=0.0001, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] sgd__alpha=0.0001, tfidf__ngram_range=(1, 1) ....................\n",
      "[CV] ..... sgd__alpha=0.0001, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] sgd__alpha=0.0001, tfidf__ngram_range=(1, 2) ....................\n",
      "[CV] ..... sgd__alpha=0.0001, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] sgd__alpha=0.0001, tfidf__ngram_range=(1, 2) ....................\n",
      "[CV] ..... sgd__alpha=0.0001, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] sgd__alpha=0.0001, tfidf__ngram_range=(1, 2) ....................\n",
      "[CV] ..... sgd__alpha=0.0001, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] sgd__alpha=0.0001, tfidf__ngram_range=(1, 2) ....................\n",
      "[CV] ..... sgd__alpha=0.0001, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] sgd__alpha=0.0001, tfidf__ngram_range=(1, 2) ....................\n",
      "[CV] ..... sgd__alpha=0.0001, tfidf__ngram_range=(1, 2), total=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:   21.6s finished\n"
     ]
    }
   ],
   "source": [
    "# Fiddling with parameters of SGDCClassifier to optimize model\n",
    "sgd_pipeline = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('sgd', SGDClassifier(random_state=27 ))\n",
    "                       ])\n",
    "\n",
    "param_grid = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "              'sgd__alpha': [1e-7, 1e-6, 1e-5, 1e-4]\n",
    "}\n",
    "\n",
    "gs_sgd = GridSearchCV(sgd_pipeline, param_grid, cv=5, verbose=2)\n",
    "gs_sgd = gs_sgd.fit(train_corpus, train_label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('tfidf',\n",
       "   TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "           stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "           token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "           vocabulary=None)),\n",
       "  ('sgd', SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "          early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "          l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "          n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "          power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "          validation_fraction=0.1, verbose=0, warm_start=False))],\n",
       " 'tfidf': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "         stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "         token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "         vocabulary=None),\n",
       " 'sgd': SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "        early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "        l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "        n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "        power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "        validation_fraction=0.1, verbose=0, warm_start=False),\n",
       " 'tfidf__analyzer': 'word',\n",
       " 'tfidf__binary': False,\n",
       " 'tfidf__decode_error': 'strict',\n",
       " 'tfidf__dtype': numpy.float64,\n",
       " 'tfidf__encoding': 'utf-8',\n",
       " 'tfidf__input': 'content',\n",
       " 'tfidf__lowercase': True,\n",
       " 'tfidf__max_df': 1.0,\n",
       " 'tfidf__max_features': None,\n",
       " 'tfidf__min_df': 1,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__preprocessor': None,\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__stop_words': None,\n",
       " 'tfidf__strip_accents': None,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tfidf__tokenizer': None,\n",
       " 'tfidf__use_idf': True,\n",
       " 'tfidf__vocabulary': None,\n",
       " 'sgd__alpha': 0.0001,\n",
       " 'sgd__average': False,\n",
       " 'sgd__class_weight': None,\n",
       " 'sgd__early_stopping': False,\n",
       " 'sgd__epsilon': 0.1,\n",
       " 'sgd__eta0': 0.0,\n",
       " 'sgd__fit_intercept': True,\n",
       " 'sgd__l1_ratio': 0.15,\n",
       " 'sgd__learning_rate': 'optimal',\n",
       " 'sgd__loss': 'hinge',\n",
       " 'sgd__max_iter': None,\n",
       " 'sgd__n_iter': None,\n",
       " 'sgd__n_iter_no_change': 5,\n",
       " 'sgd__n_jobs': None,\n",
       " 'sgd__penalty': 'l2',\n",
       " 'sgd__power_t': 0.5,\n",
       " 'sgd__random_state': 42,\n",
       " 'sgd__shuffle': True,\n",
       " 'sgd__tol': None,\n",
       " 'sgd__validation_fraction': 0.1,\n",
       " 'sgd__verbose': 0,\n",
       " 'sgd__warm_start': False}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the \"best parameters\"\n",
    "gs_sgd.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.7123333333333334\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of SGDClassifier now\n",
    "best_sgd_test_score = gs_sgd.score(test_corpus, test_label_names)\n",
    "print('Test Accuracy :', best_sgd_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] svm__C=0.01, tfidf__ngram_range=(1, 1) ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... svm__C=0.01, tfidf__ngram_range=(1, 1), total=   0.3s\n",
      "[CV] svm__C=0.01, tfidf__ngram_range=(1, 1) ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... svm__C=0.01, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] svm__C=0.01, tfidf__ngram_range=(1, 1) ..........................\n",
      "[CV] ........... svm__C=0.01, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] svm__C=0.01, tfidf__ngram_range=(1, 1) ..........................\n",
      "[CV] ........... svm__C=0.01, tfidf__ngram_range=(1, 1), total=   0.3s\n",
      "[CV] svm__C=0.01, tfidf__ngram_range=(1, 1) ..........................\n",
      "[CV] ........... svm__C=0.01, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] svm__C=0.01, tfidf__ngram_range=(1, 2) ..........................\n",
      "[CV] ........... svm__C=0.01, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] svm__C=0.01, tfidf__ngram_range=(1, 2) ..........................\n",
      "[CV] ........... svm__C=0.01, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] svm__C=0.01, tfidf__ngram_range=(1, 2) ..........................\n",
      "[CV] ........... svm__C=0.01, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] svm__C=0.01, tfidf__ngram_range=(1, 2) ..........................\n",
      "[CV] ........... svm__C=0.01, tfidf__ngram_range=(1, 2), total=   0.7s\n",
      "[CV] svm__C=0.01, tfidf__ngram_range=(1, 2) ..........................\n",
      "[CV] ........... svm__C=0.01, tfidf__ngram_range=(1, 2), total=   0.7s\n",
      "[CV] svm__C=0.1, tfidf__ngram_range=(1, 1) ...........................\n",
      "[CV] ............ svm__C=0.1, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] svm__C=0.1, tfidf__ngram_range=(1, 1) ...........................\n",
      "[CV] ............ svm__C=0.1, tfidf__ngram_range=(1, 1), total=   0.3s\n",
      "[CV] svm__C=0.1, tfidf__ngram_range=(1, 1) ...........................\n",
      "[CV] ............ svm__C=0.1, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] svm__C=0.1, tfidf__ngram_range=(1, 1) ...........................\n",
      "[CV] ............ svm__C=0.1, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] svm__C=0.1, tfidf__ngram_range=(1, 1) ...........................\n",
      "[CV] ............ svm__C=0.1, tfidf__ngram_range=(1, 1), total=   0.2s\n",
      "[CV] svm__C=0.1, tfidf__ngram_range=(1, 2) ...........................\n",
      "[CV] ............ svm__C=0.1, tfidf__ngram_range=(1, 2), total=   0.7s\n",
      "[CV] svm__C=0.1, tfidf__ngram_range=(1, 2) ...........................\n",
      "[CV] ............ svm__C=0.1, tfidf__ngram_range=(1, 2), total=   0.7s\n",
      "[CV] svm__C=0.1, tfidf__ngram_range=(1, 2) ...........................\n",
      "[CV] ............ svm__C=0.1, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] svm__C=0.1, tfidf__ngram_range=(1, 2) ...........................\n",
      "[CV] ............ svm__C=0.1, tfidf__ngram_range=(1, 2), total=   0.6s\n",
      "[CV] svm__C=0.1, tfidf__ngram_range=(1, 2) ...........................\n",
      "[CV] ............ svm__C=0.1, tfidf__ngram_range=(1, 2), total=   0.7s\n",
      "[CV] svm__C=1, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. svm__C=1, tfidf__ngram_range=(1, 1), total=   0.3s\n",
      "[CV] svm__C=1, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. svm__C=1, tfidf__ngram_range=(1, 1), total=   0.3s\n",
      "[CV] svm__C=1, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. svm__C=1, tfidf__ngram_range=(1, 1), total=   0.3s\n",
      "[CV] svm__C=1, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. svm__C=1, tfidf__ngram_range=(1, 1), total=   0.3s\n",
      "[CV] svm__C=1, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. svm__C=1, tfidf__ngram_range=(1, 1), total=   0.3s\n",
      "[CV] svm__C=1, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. svm__C=1, tfidf__ngram_range=(1, 2), total=   1.0s\n",
      "[CV] svm__C=1, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. svm__C=1, tfidf__ngram_range=(1, 2), total=   0.8s\n",
      "[CV] svm__C=1, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. svm__C=1, tfidf__ngram_range=(1, 2), total=   0.8s\n",
      "[CV] svm__C=1, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. svm__C=1, tfidf__ngram_range=(1, 2), total=   0.8s\n",
      "[CV] svm__C=1, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. svm__C=1, tfidf__ngram_range=(1, 2), total=   0.8s\n",
      "[CV] svm__C=5, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. svm__C=5, tfidf__ngram_range=(1, 1), total=   0.5s\n",
      "[CV] svm__C=5, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. svm__C=5, tfidf__ngram_range=(1, 1), total=   0.4s\n",
      "[CV] svm__C=5, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. svm__C=5, tfidf__ngram_range=(1, 1), total=   0.4s\n",
      "[CV] svm__C=5, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. svm__C=5, tfidf__ngram_range=(1, 1), total=   0.4s\n",
      "[CV] svm__C=5, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. svm__C=5, tfidf__ngram_range=(1, 1), total=   0.4s\n",
      "[CV] svm__C=5, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. svm__C=5, tfidf__ngram_range=(1, 2), total=   1.4s\n",
      "[CV] svm__C=5, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. svm__C=5, tfidf__ngram_range=(1, 2), total=   1.2s\n",
      "[CV] svm__C=5, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. svm__C=5, tfidf__ngram_range=(1, 2), total=   1.2s\n",
      "[CV] svm__C=5, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. svm__C=5, tfidf__ngram_range=(1, 2), total=   1.3s\n",
      "[CV] svm__C=5, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. svm__C=5, tfidf__ngram_range=(1, 2), total=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:   29.8s finished\n"
     ]
    }
   ],
   "source": [
    "# Repeatinf this process with the LinearSVC model\n",
    "svm_pipeline = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('svm', LinearSVC(random_state=27))\n",
    "                       ])\n",
    "\n",
    "param_grid = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "              'svm__C': [0.01, 0.1, 1, 5]\n",
    "}\n",
    "\n",
    "gs_svm = GridSearchCV(svm_pipeline, param_grid, cv=5, verbose=2)\n",
    "gs_svm = gs_svm.fit(train_corpus, train_label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('tfidf',\n",
       "   TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "           stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "           token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "           vocabulary=None)),\n",
       "  ('svm', LinearSVC(C=5, class_weight=None, dual=True, fit_intercept=True,\n",
       "        intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "        multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "        verbose=0))],\n",
       " 'tfidf': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "         stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "         token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "         vocabulary=None),\n",
       " 'svm': LinearSVC(C=5, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "      verbose=0),\n",
       " 'tfidf__analyzer': 'word',\n",
       " 'tfidf__binary': False,\n",
       " 'tfidf__decode_error': 'strict',\n",
       " 'tfidf__dtype': numpy.float64,\n",
       " 'tfidf__encoding': 'utf-8',\n",
       " 'tfidf__input': 'content',\n",
       " 'tfidf__lowercase': True,\n",
       " 'tfidf__max_df': 1.0,\n",
       " 'tfidf__max_features': None,\n",
       " 'tfidf__min_df': 1,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__preprocessor': None,\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__stop_words': None,\n",
       " 'tfidf__strip_accents': None,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tfidf__tokenizer': None,\n",
       " 'tfidf__use_idf': True,\n",
       " 'tfidf__vocabulary': None,\n",
       " 'svm__C': 5,\n",
       " 'svm__class_weight': None,\n",
       " 'svm__dual': True,\n",
       " 'svm__fit_intercept': True,\n",
       " 'svm__intercept_scaling': 1,\n",
       " 'svm__loss': 'squared_hinge',\n",
       " 'svm__max_iter': 1000,\n",
       " 'svm__multi_class': 'ovr',\n",
       " 'svm__penalty': 'l2',\n",
       " 'svm__random_state': 42,\n",
       " 'svm__tol': 0.0001,\n",
       " 'svm__verbose': 0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svm.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.7166666666666667\n"
     ]
    }
   ],
   "source": [
    "# Now this model is the most accurate\n",
    "best_svm_test_score = gs_svm.score(test_corpus, test_label_names)\n",
    "print('Test Accuracy :', best_svm_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7167\n",
      "Precision: 0.7208\n",
      "Recall: 0.7167\n",
      "F1 Score: 0.7064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "svm_predictions = gs_svm.predict(test_corpus)\n",
    "unique_classes = list(set(test_label_names))\n",
    "meu.get_metrics(true_labels=test_label_names, predicted_labels=svm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        Chardonnay       0.75      0.90      0.82       480\n",
      "   Sauvignon Blanc       0.77      0.72      0.75       191\n",
      "        Pinot Gris       0.93      0.47      0.62        60\n",
      "       White Blend       0.80      0.47      0.59        91\n",
      "              Rose       0.77      0.71      0.74       141\n",
      "            Shiraz       0.71      0.38      0.50        26\n",
      "         Zinfandel       0.55      0.38      0.45        96\n",
      "            Malbec       0.59      0.45      0.51       113\n",
      "           Moscato       0.86      0.33      0.48        18\n",
      "            Merlot       0.80      0.38      0.51       104\n",
      "         Red Blend       0.79      0.72      0.75       368\n",
      "        Pinot Noir       0.69      0.88      0.77       517\n",
      "            Muscat       0.00      0.00      0.00         7\n",
      "          Riesling       0.79      0.81      0.80       198\n",
      "      Pinot Grigio       0.78      0.50      0.61        36\n",
      "Cabernet Sauvignon       0.61      0.72      0.66       361\n",
      "             Syrah       0.69      0.54      0.61       193\n",
      "\n",
      "         micro avg       0.72      0.72      0.72      3000\n",
      "         macro avg       0.70      0.55      0.60      3000\n",
      "      weighted avg       0.72      0.72      0.71      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "meu.display_classification_report(true_labels=test_label_names, \n",
    "                                  predicted_labels=svm_predictions, classes=unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
